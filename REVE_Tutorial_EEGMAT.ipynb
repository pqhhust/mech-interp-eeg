{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pqhhust/mech-interp-eeg/blob/main/REVE_Tutorial_EEGMAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWr_rTHvx3oY"
      },
      "source": [
        "# Using REVE to classify EEG\n",
        "\n",
        "In this tutorial, we train a classification head on the REVE model to demonstrate how it can be used as a powerfull off-the-shelf feature extractor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if7ulwYjSniL"
      },
      "source": [
        "## Loading REVE\n",
        "\n",
        "To load the REVE model, go to the [Hugging Face collection](https://huggingface.co/collections/brain-bzh/reve) and select your model size (e.g. base).\n",
        "\n",
        "The model is gated so you need to accept the terms of the form on the website. In general, you will need to authenticate before using the model. You can do this in the CLI here :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZXXvgldKL-6"
      },
      "outputs": [],
      "source": [
        "!hf auth login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWcPffF6S-D2"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "import torch\n",
        "\n",
        "model = AutoModel.from_pretrained(\"brain-bzh/reve-base\", trust_remote_code=True, torch_dtype=\"auto\")\n",
        "pos_bank = AutoModel.from_pretrained(\"brain-bzh/reve-positions\", trust_remote_code=True, torch_dtype=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBucG8jCzVZW"
      },
      "outputs": [],
      "source": [
        "# Show all pre-registered positions\n",
        "print(pos_bank.get_all_positions())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygN_O-SMcKT4"
      },
      "outputs": [],
      "source": [
        "# Inspect the model\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvApQpKsURet"
      },
      "source": [
        "At this stage, the last layer of the model is `Identity()`, we will replace it with a classifier layer suited for our case.\n",
        "The dataset has 20 channels, and samples of 5s. The model output will be of size `[B, 20, 5, D]`, with `B` the batch size and `D` the hidden dimension (512 for the base model). We thus set the final layer to be of size `20*5*D`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzPriYDzURQp"
      },
      "outputs": [],
      "source": [
        "dim = 20 * 5 * 512\n",
        "\n",
        "model.final_layer = torch.nn.Sequential(\n",
        "    torch.nn.Flatten(),\n",
        "    torch.nn.RMSNorm(dim),\n",
        "    torch.nn.Dropout(0.1),\n",
        "    torch.nn.Linear(dim, 2),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuMG97sVb8Qx"
      },
      "source": [
        "NB: in practice, when using REVE on your tasks, you will only need to load it from Huggingface and modify the last layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GfTs2XTYQy2"
      },
      "source": [
        "## Training scripts\n",
        "\n",
        "You can adjust some of the training parameters here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9N1Hk4panEg"
      },
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "batch_size = 64\n",
        "n_epochs = 20\n",
        "lr = 1e-3\n",
        "positions = pos_bank([\"Fp1\", \"Fp2\", \"F3\", \"F4\", \"F7\", \"F8\", \"T3\", \"T4\", \"C3\", \"C4\", \"T5\", \"T6\", \"P3\", \"P4\", \"O1\", \"O2\", \"Fz\", \"Cz\", \"Pz\", \"A2\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qTa_ZSt76xZ"
      },
      "outputs": [],
      "source": [
        "from transformers import set_seed\n",
        "\n",
        "set_seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQA_86c1cUDU"
      },
      "source": [
        "`brain-bzh/eegmat-prepro` on Hugging Face is a preprocessed [version](https://huggingface.co/datasets/brain-bzh/eegmat-prepro) of the [EEGMAT](https://physionet.org/content/eegmat/1.0.0/) dataset, originally uploaded to PhysioNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-0x7BAsWOdR"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"brain-bzh/eegmat-prepro\")\n",
        "dataset.set_format(\"torch\", columns=[\"data\", \"labels\"])\n",
        "\n",
        "print(dataset)\n",
        "\n",
        "def collate(batch, positions):\n",
        "    x_data = torch.stack([x[\"data\"] for x in batch])\n",
        "    y_label = torch.tensor([x[\"labels\"] for x in batch])\n",
        "    positions = positions.repeat(len(batch), 1, 1)\n",
        "    return {\"sample\": x_data,\"label\": y_label.long(),\"pos\": positions}\n",
        "collate_fn = partial(collate, positions=positions)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset[\"train\"], batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = torch.utils.data.DataLoader(dataset[\"val\"], batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = torch.utils.data.DataLoader(dataset[\"test\"], batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4gTfu9Lz--K"
      },
      "source": [
        "### Training functions\n",
        "\n",
        "For simplicity, we only implement a basic training loop that does not include:\n",
        "- model souping\n",
        "- LoRA wrappers\n",
        "- Channel Mixup\n",
        "- Position augmentation\n",
        "- Two stage fine-tuning\n",
        "- Stable AdamW optimizer\n",
        "\n",
        "The results might thus differ slightly from the paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9JNfV8Jy7k3"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import balanced_accuracy_score, cohen_kappa_score, f1_score, roc_auc_score, average_precision_score\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "def train_one_epoch(model, optimizer, loader):\n",
        "    model.train()\n",
        "    pbar = tqdm(loader, desc=\"Training\", total=len(loader))\n",
        "\n",
        "    for batch_data in pbar:\n",
        "        data, target, pos = (\n",
        "            batch_data[\"sample\"].to(device, non_blocking=True),\n",
        "            batch_data[\"label\"].to(device, non_blocking=True),\n",
        "            batch_data[\"pos\"].to(device, non_blocking=True),\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        with torch.amp.autocast(dtype=torch.float16, device_type=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
        "            output = model(data, pos)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "\n",
        "def eval_model(model, loader):\n",
        "    model.eval()\n",
        "\n",
        "    y_decisions = []\n",
        "    y_targets = []\n",
        "    y_probs = []\n",
        "    score, count = 0, 0\n",
        "    pbar = tqdm(loader, desc=\"Evaluating\", total=len(loader))\n",
        "    with torch.inference_mode():\n",
        "        for batch_data in pbar:\n",
        "            data, target, pos = (\n",
        "                batch_data[\"sample\"].to(device, non_blocking=True),\n",
        "                batch_data[\"label\"].to(device, non_blocking=True),\n",
        "                batch_data[\"pos\"].to(device, non_blocking=True),\n",
        "            )\n",
        "            with torch.amp.autocast(\n",
        "                dtype=torch.float16, device_type=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "            ):\n",
        "                output = model(data, pos)\n",
        "\n",
        "            decisions = torch.argmax(output, dim=1)\n",
        "            score += (decisions == target).int().sum().item()\n",
        "            count += target.shape[0]\n",
        "            y_decisions.append(decisions)\n",
        "            y_targets.append(target)\n",
        "            y_probs.append(output)\n",
        "\n",
        "    gt = torch.cat(y_targets).cpu().numpy()\n",
        "    pr = torch.cat(y_decisions).cpu().numpy()\n",
        "    pr_probs = torch.cat(y_probs).cpu().numpy()\n",
        "    acc = score / count\n",
        "    balanced_acc = balanced_accuracy_score(gt, pr)\n",
        "    cohen_kappa = cohen_kappa_score(gt, pr)\n",
        "    f1 = f1_score(gt, pr, average=\"weighted\")\n",
        "\n",
        "    auroc = roc_auc_score(gt, pr_probs[:, 1])\n",
        "    auc_pr = average_precision_score(gt, pr_probs[:, 1])\n",
        "\n",
        "    return acc, balanced_acc, cohen_kappa, f1, auroc, auc_pr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGaGE2S5fCqU"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "We freeze the backbone and only fine-tune the classification head.\n",
        "\n",
        "The best classifier is used on the test set at the end of the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbdVK9h_evmo"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.final_layer.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.5, patience=3)\n",
        "\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "best_val_acc = 0\n",
        "best_final_layer = None\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{n_epochs}\")\n",
        "    train_one_epoch(model, optimizer, train_loader)\n",
        "    _, b_acc, _, _, _, _ = eval_model(model, val_loader)\n",
        "    if b_acc > best_val_acc:\n",
        "        best_val_acc = b_acc\n",
        "        best_final_layer = model.final_layer.state_dict()\n",
        "    print(f\"Validation balanced accuracy: {b_acc:.4f}, best: {best_val_acc:.4f}\")\n",
        "    scheduler.step(b_acc)\n",
        "\n",
        "\n",
        "model.final_layer.load_state_dict(best_final_layer)\n",
        "acc, balanced_acc, cohen_kappa, f1, auroc, auc_pr = eval_model(model, test_loader)\n",
        "\n",
        "# Results\n",
        "print(\"acc\", acc)\n",
        "print(\"balanced_acc\", balanced_acc)\n",
        "print(\"cohen_kappa\", cohen_kappa)\n",
        "print(\"f1\", f1)\n",
        "print(\"auroc\", auroc)\n",
        "print(\"auc_pr\", auc_pr)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ssm-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
